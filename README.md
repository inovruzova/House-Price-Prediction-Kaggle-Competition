This project tackles a house price regression problem as part of a Kaggle competition. The objective is to build a model that accurately predicts housing prices using various features from a real estate dataset.

Key highlights:

- Feature engineering and exploratory data analysis (EDA)
- Training multiple models (including tree ensembles like XGBoost, CatBoost, LightGBM)
- Hyperparameter tuning to improve performance
- Submitting predictions to Kaggle and optimizing for leaderboard ranking

The entire workflow is implemented in a single Jupyter Notebook, including data preprocessing, model training, evaluation, and final submission generation.
